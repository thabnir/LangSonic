{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_13 = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"en\", split=\"train\")\n",
    "ds = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"en\", token=\"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\")\n",
    "# cv_13 = load_dataset(\"common_voice_13_0\", \"en\", split=\"train\")\n",
    "dataloader = DataLoader(ds , batch_size=32) # DOES NOT WORK! Do we need auth token to access data?\n",
    "\n",
    "\n",
    "languages = [\"en\",\"fr\",\"hi\",\"ar\",\"it\",\"es\"] # languages to be used \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the input directory containing your MP3 files\n",
    "input_directory = 'E:\\\\Personal Projects\\\\maisproj\\\\fr_train_0'\n",
    "\n",
    "# Define the output directory to save the spectrograms\n",
    "output_directory = 'E:\\\\Personal Projects\\\\maisproj\\\\fr_spect_0'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert audio files to spectrograms\n",
    "def audio_to_spectrogram(audio_file, output_dir):\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(audio_file, sr=None)  # sr=None preserves the original sampling rate\n",
    "\n",
    "    # Create the spectrogram\n",
    "    plt.figure(figsize=(4, 4))  # Adjust the figure size as needed\n",
    "    S = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max), y_axis='mel', x_axis='time')\n",
    "\n",
    "    # Set the file name for the spectrogram\n",
    "    spectrogram_file = os.path.join(output_dir, os.path.basename(audio_file) + '.png')\n",
    "\n",
    "    # Save the spectrogram as an image\n",
    "    plt.savefig(spectrogram_file, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(input_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp3'):\n",
    "            audio_file = os.path.join(root, file)\n",
    "            audio_to_spectrogram(audio_file, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
